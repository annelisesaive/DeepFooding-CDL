{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f45f26d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a13ce5",
   "metadata": {},
   "source": [
    "### Cut and prepare videos \n",
    "To be run in conda prompt (with DLC env activated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2421aeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg -ss 00:02:45 -i 04C01002.avi -to 00:00:25 -c copy cut_02.avi\n",
    "[start] [file] [duration] [filename-output]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcd556f",
   "metadata": {},
   "source": [
    "### Create a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "715b2923",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"testing_dlc\"\n",
    "experimenter = \"al\"\n",
    "video_path = r\"C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\DB_videos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f14f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = deeplabcut.create_new_project(\n",
    "    project_name,\n",
    "    experimenter,\n",
    "    [video_path],\n",
    "    multianimal=False,\n",
    "    copy_videos=True,\n",
    "    videotype='.mp4',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90aa2f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = r\"C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\testing_dlc-al-2021-11-30\\config.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f34343",
   "metadata": {},
   "source": [
    "### Use pre-trained algo to label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dbe9196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\pre_trained-al-2021-11-30\\videos\"\n",
      "Created \"C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\pre_trained-al-2021-11-30\\labeled-data\"\n",
      "Created \"C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\pre_trained-al-2021-11-30\\training-datasets\"\n",
      "Created \"C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\pre_trained-al-2021-11-30\\dlc-models\"\n",
      "Copying the videos\n",
      "C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\pre_trained-al-2021-11-30\\videos\\sequence3.mp4\n",
      "Generated \"C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\pre_trained-al-2021-11-30\\config.yaml\"\n",
      "\n",
      "A new project with name pre_trained-al-2021-11-30 is created at C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n",
      "Dowloading weights...\n",
      "Downloading the model from the DeepLabCut server @Harvard -> Go Crimson!!! http://deeplabcut.rowland.harvard.edu/models/DLC_human_fullbody_resnet_101.tar.gz....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "323215360B [02:02, 2638171.53B/s]                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\pre_trained-al-2021-11-30\\dlc-models\\iteration-0\\pre_trainedNov30-trainset95shuffle1\\train\\pose_cfg.yaml\n",
      "Analyzing video...\n",
      "Using snapshot-103000 for model C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\pre_trained-al-2021-11-30\\dlc-models\\iteration-0\\pre_trainedNov30-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory...\n",
      "Starting to analyze %  C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\pre_trained-al-2021-11-30\\videos\\sequence3.mp4\n",
      "Loading  C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\pre_trained-al-2021-11-30\\videos\\sequence3.mp4\n",
      "Duration of video [s]:  30.33 , recorded with  29.97 fps!\n",
      "Overall # of frames:  909  found with (before cropping) frame dimensions:  640 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "910it [22:20,  1.47s/it]                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\pre_trained-al-2021-11-30\\videos...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Analyzing all the videos in the directory...\n",
      "Filtering with median model C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\pre_trained-al-2021-11-30\\videos\\sequence3.mp4\n",
      "Saving filtered csv poses!\n",
      "Plotting results...\n",
      "Analyzing all the videos in the directory...\n",
      "Analyzing all the videos in the directory...\n",
      "Loading  C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\pre_trained-al-2021-11-30\\videos\\sequence3.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n"
     ]
    }
   ],
   "source": [
    "project_name = \"pre_trained\"\n",
    "experimenter = \"al\"\n",
    "video_path = r\"C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\DB_videos\\sequence3.mp4\"\n",
    "config_path = deeplabcut.create_pretrained_project(\n",
    "    project_name, \n",
    "    experimenter, \n",
    "    [video_path], \n",
    "    model='full_human',\n",
    "    videotype='.mp4',\n",
    "    copy_videos=True,\n",
    "    analyzevideo=True,\n",
    "    filtered=True,\n",
    "    createlabeledvideo=True,\n",
    "    trainFraction=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028a2e36",
   "metadata": {},
   "source": [
    "### Extract video frames to annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "730b0cfc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 30.33  seconds.\n",
      "Extracting and downsampling... 909  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "909it [00:03, 229.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Frames were successfully extracted, for the videos listed in the config.yaml file.\n",
      "\n",
      "You can now label the frames using the function 'label_frames' (Note, you should label frames extracted from diverse videos (and many videos; we do not recommend training on single videos!)).\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.extract_frames(\n",
    "    config_path,\n",
    "    mode=\"automatic\",\n",
    "    algo=\"kmeans\",\n",
    "    userfeedback=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ddf320",
   "metadata": {},
   "source": [
    "### Annotate Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4befb6de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.label_frames(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330fae83",
   "metadata": {},
   "source": [
    "### Visually check annotated frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be5d8108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by al.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 39/39 [00:13<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_labels(\n",
    "    config_path,\n",
    "    draw_skeleton=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb3470a",
   "metadata": {},
   "source": [
    "### Create the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fdc933d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading a ImageNet-pretrained model from https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.0_224.tgz....\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([18, 12,  5, 17, 25, 34, 16, 11, 38, 22, 28, 13, 36,  6,  8,  1, 26,\n",
       "          29,  3, 10,  0, 24,  7, 33, 32, 27, 35, 37,  2, 19,  9, 15, 23, 20,\n",
       "           4, 21, 30]),\n",
       "   array([31, 14])))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(\n",
    "    config_path,\n",
    "    num_shuffles=1,\n",
    "    net_type=\"mobilenet_v2_1.0\",\n",
    "    augmenter_type=\"imgaug\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e3b6f2",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9862e9f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['righthand', 'lefthand', 'forkbase'],\n",
      " 'alpha_r': 0.02,\n",
      " 'apply_prob': 0.5,\n",
      " 'batch_size': 1,\n",
      " 'clahe': True,\n",
      " 'claheratio': 0.1,\n",
      " 'crop_pad': 0,\n",
      " 'crop_sampling': 'hybrid',\n",
      " 'crop_size': [400, 400],\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_testing_dlcNov30\\\\testing_dlc_al95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'edge': False,\n",
      " 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]},\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'histeq': True,\n",
      " 'histeqratio': 0.1,\n",
      " 'init_weights': 'C:\\\\Users\\\\Anne-Lise\\\\anaconda3\\\\envs\\\\DEEPLABCUT\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\mobilenet_v2_1.0_224.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'max_shift': 0.4,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_testing_dlcNov30\\\\Documentation_data-testing_dlc_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_stage': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'mobilenet_v2_1.0',\n",
      " 'num_joints': 3,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'pre_resize': [],\n",
      " 'project_path': 'C:\\\\Users\\\\Anne-Lise\\\\Dropbox\\\\Bocuse_projects\\\\03_Living_LAB\\\\testing_dlc-al-2021-11-30',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'sharpen': False,\n",
      " 'sharpenratio': 0.3,\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Anne-Lise\\\\Dropbox\\\\Bocuse_projects\\\\03_Living_LAB\\\\testing_dlc-al-2021-11-30\\\\dlc-models\\\\iteration-0\\\\testing_dlcNov30-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Batch Size is 1\n",
      "Loading ImageNet-pretrained mobilenet_v2_1.0\n",
      "Max_iters overwritten as 5000\n",
      "Save_iters overwritten as 1000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'C:\\\\Users\\\\Anne-Lise\\\\Dropbox\\\\Bocuse_projects\\\\03_Living_LAB\\\\testing_dlc-al-2021-11-30\\\\dlc-models\\\\iteration-0\\\\testing_dlcNov30-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'imgaug', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2]], 'all_joints_names': ['righthand', 'lefthand', 'forkbase'], 'alpha_r': 0.02, 'apply_prob': 0.5, 'clahe': True, 'claheratio': 0.1, 'crop_sampling': 'hybrid', 'crop_size': [400, 400], 'cropratio': 0.4, 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_testing_dlcNov30\\\\testing_dlc_al95shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'edge': False, 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]}, 'histeq': True, 'histeqratio': 0.1, 'init_weights': 'C:\\\\Users\\\\Anne-Lise\\\\anaconda3\\\\envs\\\\DEEPLABCUT\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\mobilenet_v2_1.0_224.ckpt', 'lr_init': 0.0005, 'max_input_size': 1500, 'max_shift': 0.4, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_testing_dlcNov30\\\\Documentation_data-testing_dlc_95shuffle1.pickle', 'min_input_size': 64, 'multi_stage': False, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'mobilenet_v2_1.0', 'num_joints': 3, 'pos_dist_thresh': 17, 'pre_resize': [], 'project_path': 'C:\\\\Users\\\\Anne-Lise\\\\Dropbox\\\\Bocuse_projects\\\\03_Living_LAB\\\\testing_dlc-al-2021-11-30', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'sharpen': False, 'sharpenratio': 0.3, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': (-90, 90)}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 1000 loss: 0.0387 lr: 0.005\n",
      "iteration: 2000 loss: 0.0210 lr: 0.005\n",
      "iteration: 3000 loss: 0.0180 lr: 0.005\n",
      "iteration: 4000 loss: 0.0154 lr: 0.005\n",
      "iteration: 5000 loss: 0.0136 lr: 0.005\n",
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1380, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1363, in _run_fn\n",
      "    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1456, in _call_tf_sessionrun\n",
      "    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node fifo_queue_enqueue}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\train.py\", line 82, in load_and_enqueue\n",
      "    sess.run(enqueue_op, feed_dict=food)\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 970, in run\n",
      "    result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1193, in _run\n",
      "    results = self._do_run(handle, final_targets, final_fetches,\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1373, in _do_run\n",
      "    return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1399, in _do_call\n",
      "    raise type(e)(node_def, op, message)  # pylint: disable=no-value-for-parameter\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[node fifo_queue_enqueue\n",
      " (defined at C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\train.py:68)\n",
      "]]\n",
      "\n",
      "Errors may have originated from an input operation.\n",
      "Input Source operations connected to node fifo_queue_enqueue:\n",
      "In[0] fifo_queue (defined at C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\train.py:67)\t\n",
      "In[1] Placeholder (defined at C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\train.py:60)\t\n",
      "In[2] Placeholder_1:\t\n",
      "In[3] Placeholder_2:\t\n",
      "In[4] Placeholder_3:\t\n",
      "In[5] Placeholder_4:\n",
      "\n",
      "Operation defined at: (most recent call last)\n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\runpy.py\", line 194, in _run_module_as_main\n",
      ">>>     return _run_code(code, main_globals, None,\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\runpy.py\", line 87, in _run_code\n",
      ">>>     exec(code, run_globals)\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      ">>>     app.launch_new_instance()\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      ">>>     app.start()\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      ">>>     self.io_loop.start()\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      ">>>     self.asyncio_loop.run_forever()\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n",
      ">>>     self._run_once()\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n",
      ">>>     handle._run()\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\asyncio\\events.py\", line 81, in _run\n",
      ">>>     self._context.run(self._callback, *self._args)\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n",
      ">>>     await self.process_one()\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n",
      ">>>     await dispatch(*args)\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n",
      ">>>     await result\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n",
      ">>>     reply_content = await reply_content\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n",
      ">>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n",
      ">>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n",
      ">>>     result = self._run_cell(\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      ">>>     return runner(coro)\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      ">>>     coro.send(None)\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n",
      ">>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      ">>>     if (await self.run_code(code, result,  async_=asy)):\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      ">>>     exec(code_obj, self.user_global_ns, self.user_ns)\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\AppData\\Local\\Temp/ipykernel_16312/1414131364.py\", line 1, in <module>\n",
      ">>>     deeplabcut.train_network(\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 176, in train_network\n",
      ">>>     train(\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\train.py\", line 171, in train\n",
      ">>>     batch, enqueue_op, placeholders = setup_preloading(batch_spec)\n",
      ">>> \n",
      ">>>   File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\train.py\", line 68, in setup_preloading\n",
      ">>>     enqueue_op = q.enqueue(placeholders_list)\n",
      ">>> \n",
      "\n",
      "Original stack trace for 'fifo_queue_enqueue':\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Anne-Lise\\AppData\\Local\\Temp/ipykernel_16312/1414131364.py\", line 1, in <module>\n",
      "    deeplabcut.train_network(\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 176, in train_network\n",
      "    train(\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\train.py\", line 171, in train\n",
      "    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\train.py\", line 68, in setup_preloading\n",
      "    enqueue_op = q.enqueue(placeholders_list)\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 350, in enqueue\n",
      "    return gen_data_flow_ops.queue_enqueue_v2(\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 4062, in queue_enqueue_v2\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 744, in _apply_op_helper\n",
      "    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3697, in _create_op_internal\n",
      "    ret = Operation(\n",
      "  File \"C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2101, in __init__\n",
      "    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(\n",
    "    config_path,\n",
    "    saveiters=1000,\n",
    "    maxiters=5000,\n",
    "    allow_growth=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48b85b7",
   "metadata": {},
   "source": [
    "### Evaluate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f74a13c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['righthand', 'lefthand', 'forkbase'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_testing_dlcNov30\\\\testing_dlc_al95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Anne-Lise\\\\anaconda3\\\\envs\\\\DEEPLABCUT\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\mobilenet_v2_1.0_224.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'mobilenet_v2_1.0',\n",
      " 'num_joints': 3,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Anne-Lise\\\\Dropbox\\\\Bocuse_projects\\\\03_Living_LAB\\\\testing_dlc-al-2021-11-30\\\\dlc-models\\\\iteration-0\\\\testing_dlcNov30-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DLC_mobnet_100_testing_dlcNov30shuffle1_5000  with # of training iterations: 5000\n",
      "This net has already been evaluated!\n",
      "Plotting...(attention scale might be inconsistent in comparison to when data was analyzed; i.e. if you used rescale)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 39/39 [00:17<00:00,  2.21it/s]\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(\n",
    "    config_path,\n",
    "    plotting=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a451cca",
   "metadata": {},
   "source": [
    "### Analyze a video (extracts detections and association costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4929557b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['righthand', 'lefthand', 'forkbase'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_testing_dlcNov30\\\\testing_dlc_al95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Anne-Lise\\\\anaconda3\\\\envs\\\\DEEPLABCUT\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\mobilenet_v2_1.0_224.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'mobilenet_v2_1.0',\n",
      " 'num_joints': 3,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Anne-Lise\\\\Dropbox\\\\Bocuse_projects\\\\03_Living_LAB\\\\testing_dlc-al-2021-11-30\\\\dlc-models\\\\iteration-0\\\\testing_dlcNov30-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-5000 for model C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\testing_dlc-al-2021-11-30\\dlc-models\\iteration-0\\testing_dlcNov30-trainset95shuffle1\n",
      "Starting analysis in dynamic cropping mode with parameters: (True, 0.5, 10)\n",
      "Switching batchsize to 1, num_outputs (per animal) to 1 and TFGPUinference to False (all these features are not supported in this mode).\n",
      "Analyzing all the videos in the directory...\n",
      "Starting to analyze %  C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\DB_videos\\sequence3.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_mobnet_100_testing_dlcNov30shuffle1_5000'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.analyze_videos(\n",
    "    config_path,\n",
    "    [video_path],\n",
    "    videotype='mp4',\n",
    "    dynamic=(True,.5,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad9b4c6",
   "metadata": {},
   "source": [
    "### Filter predictions with a median filter or SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbfe14bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory...\n",
      "Filtering with arima model C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\DB_videos\\sequence3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anne-Lise\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n"
     ]
    }
   ],
   "source": [
    "#creates a filtered h5 data with all behavioral predictions\n",
    "deeplabcut.filterpredictions(\n",
    "    config_path, [video_path], videotype='mp4',\n",
    "    shuffle=1, trainingsetindex=0, \n",
    "    filtertype='arima', p_bound=0.01, ARdegree=3, MAdegree=1, alpha=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537f8a2b",
   "metadata": {},
   "source": [
    "### Plot trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7e49dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory...\n",
      "Loading  C:\\Users\\Anne-Lise\\Dropbox\\Bocuse_projects\\03_Living_LAB\\DB_videos\\sequence3.mp4 and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.plot_trajectories(\n",
    "    config_path, [video_path], videotype='mp4',\n",
    "    filtered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74600985",
   "metadata": {},
   "source": [
    "### Create Labeled Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b546c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory...\n"
     ]
    }
   ],
   "source": [
    "# Plotting the labels on top of the frame and creating a video\n",
    "# high-quality: save_frames=True\n",
    "\n",
    "deeplabcut.create_labeled_video(\n",
    "    config_path, [video_path], #save_frames = True,\n",
    "    videotype = 'avi', filtered=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DEEPLABCUT] *",
   "language": "python",
   "name": "conda-env-DEEPLABCUT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
